{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5794207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1217be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRecommender(ABC):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.train_df = None\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"Treina o modelo com os dados de treino.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def recommend(self, author_id, top_n=10):\n",
    "        \"\"\"Retorna uma lista de author_ids recomendados.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f903cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopologyRecommender(BaseRecommender):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Topology (Graph Coauthor)\")\n",
    "        self.graph = defaultdict(set)\n",
    "        self.popular_authors = []\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        self.train_df = train_df\n",
    "        print(f\"[{self.name}] Construindo grafo...\")\n",
    "        \n",
    "        # Construção do Grafo\n",
    "        for _, group in train_df.groupby('work_id'):\n",
    "            authors = group['author_id'].tolist()\n",
    "            if len(authors) > 1:\n",
    "                for u, v in itertools.permutations(authors, 2):\n",
    "                    self.graph[u].add(v)\n",
    "        \n",
    "        # Cálculo de Popularidade (para fallback)\n",
    "        popularity_counter = Counter()\n",
    "        for author, neighbors in self.graph.items():\n",
    "            popularity_counter[author] = len(neighbors)\n",
    "        self.popular_authors = [auth for auth, _ in popularity_counter.most_common()]\n",
    "        print(f\"[{self.name}] Grafo construído com {len(self.graph)} autores.\")\n",
    "\n",
    "    def recommend(self, author_id, top_n=10):\n",
    "        recommendations = []\n",
    "        current_coauthors = self.graph.get(author_id, set())\n",
    "        \n",
    "        # Lógica de Amigos em Comum (2 hops)\n",
    "        if author_id in self.graph:\n",
    "            candidates = []\n",
    "            for neighbor in current_coauthors:\n",
    "                neighbors_of_neighbor = self.graph.get(neighbor, set())\n",
    "                for candidate in neighbors_of_neighbor:\n",
    "                    if candidate != author_id and candidate not in current_coauthors:\n",
    "                        candidates.append(candidate)\n",
    "            \n",
    "            recommendations = [c[0] for c in Counter(candidates).most_common(top_n)]\n",
    "        \n",
    "        # Fallback: Populares\n",
    "        if len(recommendations) < top_n:\n",
    "            for pop in self.popular_authors:\n",
    "                if pop != author_id and pop not in recommendations and pop not in current_coauthors:\n",
    "                    recommendations.append(pop)\n",
    "                    if len(recommendations) >= top_n:\n",
    "                        break\n",
    "                        \n",
    "        return recommendations[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e74db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentSciBERTRecommender(BaseRecommender):\n",
    "    def __init__(self, model_name='allenai/scibert_scivocab_uncased', cache_path='scibert_embeddings.pkl'):\n",
    "        super().__init__(\"Content-Based (SciBERT)\")\n",
    "        self.model_name = model_name\n",
    "        self.cache_path = cache_path\n",
    "        self.encoder = None\n",
    "        self.author_embeddings = {} \n",
    "        self.knn_model = None\n",
    "        self.author_ids_index = []\n",
    "        \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"[{self.name}] Device selecionado: {self.device.upper()}\")\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        work_id_to_emb = self._load_embeddings()\n",
    "        \n",
    "        unique_works = train_df[['work_id', 'title', 'abstract']].drop_duplicates()\n",
    "        \n",
    "        if work_id_to_emb is None:\n",
    "            print(f\"[{self.name}] Gerando embeddings na {self.device.upper()}...\")\n",
    "            self.encoder = SentenceTransformer(self.model_name, device=self.device)\n",
    "            \n",
    "            unique_works['text'] = unique_works['title'] + \". \" + unique_works['abstract'].fillna('')\n",
    "            \n",
    "            work_embeddings = self.encoder.encode(\n",
    "                unique_works['text'].tolist(), \n",
    "                batch_size=32, \n",
    "                show_progress_bar=True,\n",
    "                device=self.device\n",
    "            )\n",
    "            \n",
    "            work_id_to_emb = {wid: emb for wid, emb in zip(unique_works['work_id'], work_embeddings)}\n",
    "            self._save_embeddings(work_id_to_emb)\n",
    "        else:\n",
    "            print(f\"[{self.name}] Embeddings carregados do cache.\")\n",
    "\n",
    "        print(f\"[{self.name}] Consolidadando perfis de autores...\")\n",
    "        \n",
    "        author_groups = train_df.groupby('author_id')['work_id'].apply(list)\n",
    "        \n",
    "        author_vectors = []\n",
    "        self.author_ids_index = []\n",
    "        \n",
    "        for author_id, work_ids in author_groups.items():\n",
    "            vectors = [work_id_to_emb[wid] for wid in work_ids if wid in work_id_to_emb]\n",
    "            \n",
    "            if vectors:\n",
    "                mean_vector = np.mean(vectors, axis=0)\n",
    "                author_vectors.append(mean_vector)\n",
    "                self.author_ids_index.append(author_id)\n",
    "        \n",
    "        self.author_embeddings = np.array(author_vectors)\n",
    "        \n",
    "        # O KNN do scikit-learn roda em CPU, mas é muito rápido para vetores já prontos\n",
    "        self.knn_model = NearestNeighbors(n_neighbors=50, metric='cosine', n_jobs=-1)\n",
    "        self.knn_model.fit(self.author_embeddings)\n",
    "        print(f\"[{self.name}] Treino finalizado. {len(self.author_ids_index)} perfis.\")\n",
    "\n",
    "    def recommend(self, author_id, top_n=10):\n",
    "        try:\n",
    "            author_idx = self.author_ids_index.index(author_id)\n",
    "        except ValueError:\n",
    "            return []\n",
    "            \n",
    "        author_vector = self.author_embeddings[author_idx].reshape(1, -1)\n",
    "        distances, indices = self.knn_model.kneighbors(author_vector, n_neighbors=top_n+1)\n",
    "        \n",
    "        recommendations = []\n",
    "        for idx in indices[0]:\n",
    "            rec_author = self.author_ids_index[idx]\n",
    "            if rec_author != author_id:\n",
    "                recommendations.append(rec_author)\n",
    "                \n",
    "        return recommendations[:top_n]\n",
    "    \n",
    "    def get_author_vector(self, author_id):\n",
    "        try:\n",
    "            idx = self.author_ids_index.index(author_id)\n",
    "            return self.author_embeddings[idx]\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    def _save_embeddings(self, data):\n",
    "        with open(self.cache_path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "\n",
    "    def _load_embeddings(self):\n",
    "        if os.path.exists(self.cache_path):\n",
    "            with open(self.cache_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e971eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender(BaseRecommender):\n",
    "    def __init__(self, topology_model, content_model, alpha=0.8):\n",
    "        \"\"\"\n",
    "        alpha: Peso dado ao modelo de Topologia (0.0 a 1.0).\n",
    "               Se alpha=0.8, vale 80% Topologia e 20% Conteúdo.\n",
    "               Dado que Topologia performou melhor, recomendo alpha alto (0.7 a 0.9).\n",
    "        \"\"\"\n",
    "        super().__init__(\"Hybrid (Topology + Content)\")\n",
    "        self.topo_model = topology_model\n",
    "        self.content_model = content_model\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        if not self.topo_model.graph:\n",
    "            self.topo_model.fit(train_df)\n",
    "        if len(self.content_model.author_embeddings) == 0:\n",
    "            self.content_model.fit(train_df)\n",
    "            \n",
    "    def recommend(self, author_id, top_n=10):\n",
    "        pool_size = top_n * 3 \n",
    "        \n",
    "        topo_candidates = {}\n",
    "        if author_id in self.topo_model.graph:\n",
    "            current_coauthors = self.topo_model.graph[author_id]\n",
    "            candidates = []\n",
    "            for neighbor in current_coauthors:\n",
    "                for candidate in self.topo_model.graph.get(neighbor, set()):\n",
    "                    if candidate != author_id and candidate not in current_coauthors:\n",
    "                        candidates.append(candidate)\n",
    "            \n",
    "            topo_counts = Counter(candidates)\n",
    "            if topo_counts:\n",
    "                max_count = max(topo_counts.values())\n",
    "                topo_candidates = {auth: count/max_count for auth, count in topo_counts.items()}\n",
    "\n",
    "        content_candidates = {}\n",
    "        if author_id in self.content_model.author_ids_index:\n",
    "            try:\n",
    "                auth_idx = self.content_model.author_ids_index.index(author_id)\n",
    "                auth_vec = self.content_model.author_embeddings[auth_idx].reshape(1, -1)\n",
    "                \n",
    "                dists, indices = self.content_model.knn_model.kneighbors(auth_vec, n_neighbors=pool_size)\n",
    "                \n",
    "                for d, idx in zip(dists[0], indices[0]):\n",
    "                    rec_auth = self.content_model.author_ids_index[idx]\n",
    "                    if rec_auth != author_id:\n",
    "                        sim_score = 1.0 - d \n",
    "                        content_candidates[rec_auth] = sim_score\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        final_scores = defaultdict(float)\n",
    "        \n",
    "        all_candidates = set(topo_candidates.keys()) | set(content_candidates.keys())\n",
    "        \n",
    "        for cand in all_candidates:\n",
    "            score_t = topo_candidates.get(cand, 0.0)\n",
    "            score_c = content_candidates.get(cand, 0.0)\n",
    "            \n",
    "            final_scores[cand] = (self.alpha * score_t) + ((1 - self.alpha) * score_c)\n",
    "            \n",
    "        sorted_recs = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [auth for auth, score in sorted_recs[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a0b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class HybridRecommenderFilter(BaseRecommender):\n",
    "    def __init__(self, topology_model, content_model, filter_k=50):\n",
    "        \"\"\"\n",
    "        filter_k: Quantos candidatos a topologia deve buscar inicialmente.\n",
    "                  Quanto maior, mais chance do Content Model encontrar alguém relevante que estava 'escondido' lá embaixo na lista.\n",
    "        \"\"\"\n",
    "        super().__init__(\"Hybrid (Topo Filter + Content Rank)\")\n",
    "        self.topo_model = topology_model\n",
    "        self.content_model = content_model\n",
    "        self.filter_k = filter_k\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        pass\n",
    "\n",
    "    def recommend(self, author_id, top_n=10):\n",
    "        candidates = self.topo_model.recommend(author_id, top_n=self.filter_k)\n",
    "        \n",
    "        if not candidates:\n",
    "            return []\n",
    "            \n",
    "        source_vector = self.content_model.get_author_vector(author_id)\n",
    "        \n",
    "        if source_vector is None:\n",
    "            return candidates[:top_n]\n",
    "            \n",
    "        candidate_scores = []\n",
    "        \n",
    "        for cand_id in candidates:\n",
    "            cand_vector = self.content_model.get_author_vector(cand_id)\n",
    "            \n",
    "            if cand_vector is not None:\n",
    "                sim = cosine_similarity(source_vector.reshape(1, -1), cand_vector.reshape(1, -1))[0][0]\n",
    "                candidate_scores.append((cand_id, sim))\n",
    "            else:\n",
    "                candidate_scores.append((cand_id, -1))\n",
    "        \n",
    "        candidate_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        final_recs = [cand for cand, score in candidate_scores]\n",
    "        return final_recs[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48103f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, test_ground_truth, train_graph_check, K_values=[5, 10]):\n",
    "    results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"\\nAvaliando modelo: {model.name}...\")\n",
    "        model_metrics = {k: {'precision': [], 'recall': []} for k in K_values}\n",
    "        \n",
    "        for author_id, actual_new_coauthors in test_ground_truth.items():\n",
    "            max_k = max(K_values)\n",
    "            recs = model.recommend(author_id, top_n=max_k)\n",
    "            \n",
    "            past_coauthors = train_graph_check.get(author_id, set())\n",
    "            recs = [r for r in recs if r not in past_coauthors]\n",
    "            \n",
    "            for k in K_values:\n",
    "                top_k_recs = recs[:k]\n",
    "                hits = len(set(top_k_recs) & actual_new_coauthors)\n",
    "                \n",
    "                p = hits / k if k > 0 else 0\n",
    "                r = hits / len(actual_new_coauthors) if len(actual_new_coauthors) > 0 else 0\n",
    "                \n",
    "                model_metrics[k]['precision'].append(p)\n",
    "                model_metrics[k]['recall'].append(r)\n",
    "        \n",
    "        # Média final\n",
    "        results[model.name] = {}\n",
    "        for k in K_values:\n",
    "            avg_p = np.mean(model_metrics[k]['precision'])\n",
    "            avg_r = np.mean(model_metrics[k]['recall'])\n",
    "            f1 = 2 * (avg_p * avg_r) / (avg_p + avg_r) if (avg_p + avg_r) > 0 else 0\n",
    "            \n",
    "            results[model.name][k] = {'P': avg_p, 'R': avg_r, 'F1': f1}\n",
    "            print(f\"  K={k}: Precision={avg_p:.4f}, Recall={avg_r:.4f}, F1={f1:.4f}\")\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aefd7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison(results, figsize=(15, 5)):\n",
    "    model_names = list(results.keys())\n",
    "    k_values = sorted(list(results[model_names[0]].keys()))\n",
    "    \n",
    "    # Preparar dados para cada métrica\n",
    "    metrics_data = {\n",
    "        'Precision': {model: [results[model][k]['P'] for k in k_values] for model in model_names},\n",
    "        'Recall': {model: [results[model][k]['R'] for k in k_values] for model in model_names},\n",
    "        'F1-Score': {model: [results[model][k]['F1'] for k in k_values] for model in model_names}\n",
    "    }\n",
    "    \n",
    "    # Criar figura com 3 subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    fig.suptitle('Comparação de Modelos de Link Prediction', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Cores e estilos para cada modelo\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "    markers = ['o', 's', '^', 'D', 'v']\n",
    "    \n",
    "    # Plotar cada métrica\n",
    "    for idx, (metric_name, data) in enumerate(metrics_data.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for i, model in enumerate(model_names):\n",
    "            ax.plot(\n",
    "                k_values, \n",
    "                data[model], \n",
    "                marker=markers[i % len(markers)],\n",
    "                label=model,\n",
    "                color=colors[i % len(colors)],\n",
    "                linewidth=2,\n",
    "                markersize=8\n",
    "            )\n",
    "        \n",
    "        ax.set_xlabel('K (Top-K)', fontsize=11)\n",
    "        ax.set_ylabel(metric_name, fontsize=11)\n",
    "        ax.set_title(f'{metric_name} por K', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.set_xticks(k_values)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BSBCo\\AppData\\Local\\Temp\\ipykernel_5456\\3401278603.py:2: DtypeWarning: Columns (0: is_retracted) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  works_df = pd.read_csv('database_50k/works.csv')\n"
     ]
    }
   ],
   "source": [
    "database_path = 'database_50k'\n",
    "authors_df = pd.read_csv(f'{database_path}/authorships.csv')\n",
    "works_df = pd.read_csv(f'{database_path}/works.csv')\n",
    "\n",
    "merged_df = authors_df.merge(\n",
    "    works_df[['id', 'publication_date', 'title', 'abstract', 'language']], \n",
    "    left_on='work_id', right_on='id'\n",
    ")\n",
    "merged_df['publication_date'] = pd.to_datetime(merged_df['publication_date'], errors='coerce')\n",
    "merged_df = merged_df.dropna(subset=['publication_date', 'author_id', 'title', 'abstract', 'language']).drop(columns=['id'])\n",
    "merged_df = merged_df[merged_df['language'] == 'en']\n",
    "\n",
    "unique_works = merged_df[['work_id', 'publication_date']].drop_duplicates().sort_values('publication_date')\n",
    "split_idx = int(len(unique_works) * 0.8)\n",
    "\n",
    "train_work_ids = set(unique_works.iloc[:split_idx]['work_id'])\n",
    "test_work_ids = set(unique_works.iloc[split_idx:]['work_id'])\n",
    "\n",
    "train_df = merged_df[merged_df['work_id'].isin(train_work_ids)]\n",
    "test_df = merged_df[merged_df['work_id'].isin(test_work_ids)]\n",
    "\n",
    "def build_graph(df):\n",
    "    graph = defaultdict(set)\n",
    "    for _, group in df.groupby('work_id'):\n",
    "        authors = group['author_id'].tolist()\n",
    "        \n",
    "        if len(authors) > 1:\n",
    "            for u, v in itertools.permutations(authors, 2):\n",
    "                graph[u].add(v)\n",
    "\n",
    "    return graph\n",
    "\n",
    "train_graph = build_graph(train_df)\n",
    "test_graph_raw = build_graph(test_df)\n",
    "\n",
    "test_ground_truth = defaultdict(set)\n",
    "\n",
    "for author, coauthors in test_graph_raw.items():\n",
    "    # Pega quem o autor colaborou no futuro\n",
    "    future_coauthors = coauthors\n",
    "    \n",
    "    # Remove quem ele já conhecia no passado (não é predição nova)\n",
    "    past_coauthors = train_graph.get(author, set())\n",
    "    new_links = future_coauthors - past_coauthors\n",
    "    \n",
    "    if new_links:\n",
    "        test_ground_truth[author] = new_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b084bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Content-Based (SciBERT)] Device selecionado: CUDA\n",
      "[Topology (Graph Coauthor)] Construindo grafo...\n",
      "[Topology (Graph Coauthor)] Grafo construído com 25260 autores.\n",
      "[Content-Based (SciBERT)] Embeddings carregados do cache.\n",
      "[Content-Based (SciBERT)] Consolidadando perfis de autores...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m models = [topo_model, content_model, hybrid_model, hybrid_model_filter]\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     11\u001b[39m metrics = evaluate_models(models, test_ground_truth, train_graph, K_values=[\u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m50\u001b[39m])\n\u001b[32m     12\u001b[39m plot_model_comparison(metrics)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mContentSciBERTRecommender.fit\u001b[39m\u001b[34m(self, train_df)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# O KNN do scikit-learn roda em CPU, mas é muito rápido para vetores já prontos\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28mself\u001b[39m.knn_model = NearestNeighbors(n_neighbors=\u001b[32m50\u001b[39m, metric=\u001b[33m'\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mknn_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauthor_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Treino finalizado. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.author_ids_index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m perfis.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\BSBCo\\dev\\link-prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\BSBCo\\dev\\link-prediction\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:179\u001b[39m, in \u001b[36mNearestNeighbors.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[32m    160\u001b[39m     prefer_skip_nested_validation=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    161\u001b[39m )\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    163\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[32m    164\u001b[39m \n\u001b[32m    165\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    177\u001b[39m \u001b[33;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\BSBCo\\dev\\link-prediction\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:519\u001b[39m, in \u001b[36mNeighborsBase._fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    518\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m         X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28mself\u001b[39m._check_algorithm_metric()\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\BSBCo\\dev\\link-prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\BSBCo\\dev\\link-prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1060\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1054\u001b[39m             msg = (\n\u001b[32m   1055\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1056\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1057\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1058\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mif it contains a single sample.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1059\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1060\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1062\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array.dtype, \u001b[33m\"\u001b[39m\u001b[33mkind\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mUSV\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1064\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1065\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1066\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "topo_model = TopologyRecommender()\n",
    "content_model = ContentSciBERTRecommender(model_name='allenai/scibert_scivocab_uncased', cache_path=f'{database_path}/scibert_embeddings.pkl')\n",
    "hybrid_model = HybridRecommender(topo_model, content_model, alpha=0.8)\n",
    "hybrid_model_filter = HybridRecommenderFilter(topo_model, content_model, filter_k=100)\n",
    "\n",
    "models = [topo_model, content_model, hybrid_model, hybrid_model_filter]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(train_df) \n",
    "    \n",
    "metrics = evaluate_models(models, test_ground_truth, train_graph, K_values=[5, 10, 20, 50])\n",
    "plot_model_comparison(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
