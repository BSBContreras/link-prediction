{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41bcf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de trabalhos: 3574\n",
      "Trabalhos no Treino (80%): 2859\n",
      "\n",
      "Recomendações para Luciana Principal Antunes (https://openalex.org/A5069790395):\n",
      "Autor: Jesus Aparecido Ferro | Coautores em comum: 12\n",
      "Autor: Dirce Maria Carraro | Coautores em comum: 10\n",
      "Autor: Leandro Márcio Moreira | Coautores em comum: 10\n",
      "Autor: Suzan Pantaroto de Vasconcellos | Coautores em comum: 10\n",
      "Autor: Aline Da Silva | Coautores em comum: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# 1. Carregamento dos dados\n",
    "# Certifique-se de que os caminhos dos arquivos estão corretos\n",
    "authors_df = pd.read_csv('database/authorships.csv')\n",
    "works_df = pd.read_csv('database/works.csv')\n",
    "\n",
    "# 2. Pré-processamento e Junção\n",
    "# Precisamos da data de publicação associada a cada autoria\n",
    "# Fazemos um merge entre a tabela de autores e a tabela de trabalhos\n",
    "merged_df = authors_df.merge(\n",
    "    works_df[['id', 'publication_date']], \n",
    "    left_on='work_id', \n",
    "    right_on='id'\n",
    ")\n",
    "\n",
    "# Converter coluna de data para datetime para ordenação correta\n",
    "merged_df['publication_date'] = pd.to_datetime(merged_df['publication_date'], errors='coerce')\n",
    "\n",
    "# Remover linhas sem data (se houver) para garantir a ordem temporal\n",
    "merged_df = merged_df.dropna(subset=['publication_date'])\n",
    "\n",
    "# 3. Corte Temporal (80% Treino / 20% Teste)\n",
    "# É importante dividir baseado nas OBRAS (works), não nas linhas, para não quebrar uma obra no meio\n",
    "unique_works = merged_df[['work_id', 'publication_date']].drop_duplicates().sort_values('publication_date')\n",
    "\n",
    "# Índice de corte (80%)\n",
    "split_idx = int(len(unique_works) * 0.8)\n",
    "\n",
    "# Pegamos os IDs das obras que compõem os 80% mais antigos\n",
    "train_work_ids = set(unique_works.iloc[:split_idx]['work_id'])\n",
    "\n",
    "# Filtramos o DataFrame principal para manter apenas essas obras no treino\n",
    "train_df = merged_df[merged_df['work_id'].isin(train_work_ids)].copy()\n",
    "\n",
    "print(f\"Total de trabalhos: {len(unique_works)}\")\n",
    "print(f\"Trabalhos no Treino (80%): {len(train_work_ids)}\")\n",
    "\n",
    "# 4. Construção do Grafo de Coautoria (Apenas dados de Treino)\n",
    "# Usamos um dicionário onde a chave é o ID do autor e o valor é um conjunto (set) de coautores\n",
    "coauthors_graph = defaultdict(set)\n",
    "\n",
    "# Agrupamos por trabalho para identificar quem escreveu junto\n",
    "for work_id, group in train_df.groupby('work_id'):\n",
    "    authors_in_paper = group['author_id'].tolist()\n",
    "    \n",
    "    # Só há coautoria se houver mais de 1 autor\n",
    "    # (Otimização: papers com muitos autores (ex: 500+) podem deixar o loop lento, \n",
    "    # você pode colocar um limite 'if len(authors_in_paper) < 50:' se necessário)\n",
    "    if len(authors_in_paper) > 1:\n",
    "        # Gera todas as permutações de pares (A, B) e (B, A)\n",
    "        for u, v in itertools.permutations(authors_in_paper, 2):\n",
    "            coauthors_graph[u].add(v)\n",
    "\n",
    "# 5. Função de Recomendação (Common Neighbors)\n",
    "def recommend_coauthors(author_id, graph, top_n=5):\n",
    "    \"\"\"\n",
    "    Recomenda autores que não são vizinhos diretos, mas compartilham vizinhos.\n",
    "    Ordena pelo número de vizinhos compartilhados.\n",
    "    \"\"\"\n",
    "    if author_id not in graph:\n",
    "        return [] # Autor não tem coautorias no conjunto de treino\n",
    "    \n",
    "    current_coauthors = graph[author_id]\n",
    "    candidates = []\n",
    "    \n",
    "    # Para cada coautor que o autor A já tem...\n",
    "    for neighbor in current_coauthors:\n",
    "        # Olhamos os coautores desse coautor (vizinhos dos vizinhos)\n",
    "        neighbors_of_neighbor = graph.get(neighbor, set())\n",
    "        \n",
    "        for candidate in neighbors_of_neighbor:\n",
    "            # Critérios de exclusão:\n",
    "            # 1. Não pode ser o próprio autor\n",
    "            # 2. Não pode ser alguém com quem ele JÁ escreveu (vizinho direto)\n",
    "            if candidate != author_id and candidate not in current_coauthors:\n",
    "                candidates.append(candidate)\n",
    "    \n",
    "    # Contamos a frequência (quantos 'neighbor' em comum levaram a este 'candidate')\n",
    "    candidate_counts = Counter(candidates)\n",
    "    \n",
    "    # Retorna os top N ordenados por maior número de coautores em comum\n",
    "    return candidate_counts.most_common(top_n)\n",
    "\n",
    "# --- Exemplo de Uso ---\n",
    "\n",
    "# Escolha um autor para testar (substitua pelo ID desejado)\n",
    "# Exemplo: pegando o primeiro autor que aparece no dataset de treino\n",
    "sample_author_id = train_df['author_id'].iloc[0] \n",
    "sample_author_name = train_df[train_df['author_id'] == sample_author_id]['author_name'].iloc[0]\n",
    "\n",
    "recommendations = recommend_coauthors(sample_author_id, coauthors_graph)\n",
    "\n",
    "print(f\"\\nRecomendações para {sample_author_name} ({sample_author_id}):\")\n",
    "for rec_id, score in recommendations:\n",
    "    # Busca o nome do recomendado para exibir\n",
    "    rec_name = authors_df[authors_df['author_id'] == rec_id]['author_name'].iloc[0]\n",
    "    print(f\"Autor: {rec_name} | Coautores em comum: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd657bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autores no treino: 7806\n",
      "Autores com novas conexões no teste (para avaliar): 2914\n",
      "------------------------------\n",
      "Resultados da Avaliação (Top-10):\n",
      "Precision: 0.0075 (De cada 10 sugeridos, ~0.1 são aceitos)\n",
      "Recall:    0.0095 (O modelo encontra ~0.9% dos novos parceiros)\n",
      "F1-Score:  0.0084\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# --- ETAPAS ANTERIORES (CARREGAMENTO E SPLIT) ---\n",
    "# (Repetindo o setup essencial para o código ser autossuficiente)\n",
    "\n",
    "authors_df = pd.read_csv('database/authorships.csv')\n",
    "works_df = pd.read_csv('database/works.csv')\n",
    "\n",
    "merged_df = authors_df.merge(\n",
    "    works_df[['id', 'publication_date']], \n",
    "    left_on='work_id', right_on='id'\n",
    ")\n",
    "merged_df['publication_date'] = pd.to_datetime(merged_df['publication_date'], errors='coerce')\n",
    "merged_df = merged_df.dropna(subset=['publication_date'])\n",
    "\n",
    "unique_works = merged_df[['work_id', 'publication_date']].drop_duplicates().sort_values('publication_date')\n",
    "split_idx = int(len(unique_works) * 0.8)\n",
    "\n",
    "# IDs de Treino e Teste\n",
    "train_work_ids = set(unique_works.iloc[:split_idx]['work_id'])\n",
    "test_work_ids = set(unique_works.iloc[split_idx:]['work_id'])\n",
    "\n",
    "train_df = merged_df[merged_df['work_id'].isin(train_work_ids)]\n",
    "test_df = merged_df[merged_df['work_id'].isin(test_work_ids)]\n",
    "\n",
    "# --- 1. CONSTRUÇÃO DOS GRAFOS ---\n",
    "\n",
    "# Função auxiliar para criar grafo\n",
    "def build_graph(df):\n",
    "    graph = defaultdict(set)\n",
    "    for _, group in df.groupby('work_id'):\n",
    "        authors = group['author_id'].tolist()\n",
    "        if len(authors) > 1:\n",
    "            for u, v in itertools.permutations(authors, 2):\n",
    "                graph[u].add(v)\n",
    "    return graph\n",
    "\n",
    "# Grafo de Treino (O que o modelo conhece)\n",
    "train_graph = build_graph(train_df)\n",
    "\n",
    "# Grafo de Teste (O futuro real)\n",
    "test_graph_raw = build_graph(test_df)\n",
    "\n",
    "# --- 2. DEFINIR O GROUND TRUTH (NOVAS RELAÇÕES APENAS) ---\n",
    "# Queremos prever conexões que NÃO existiam no treino e apareceram no teste.\n",
    "test_ground_truth = defaultdict(set)\n",
    "\n",
    "for author, coauthors in test_graph_raw.items():\n",
    "    # Pega quem o autor colaborou no futuro\n",
    "    future_coauthors = coauthors\n",
    "    # Remove quem ele JÁ conhecia no passado (não é predição nova)\n",
    "    past_coauthors = train_graph.get(author, set())\n",
    "    \n",
    "    new_links = future_coauthors - past_coauthors\n",
    "    \n",
    "    if new_links:\n",
    "        test_ground_truth[author] = new_links\n",
    "\n",
    "print(f\"Autores no treino: {len(train_graph)}\")\n",
    "print(f\"Autores com novas conexões no teste (para avaliar): {len(test_ground_truth)}\")\n",
    "\n",
    "# --- 3. FUNÇÃO DE RECOMENDAÇÃO (A mesma anterior) ---\n",
    "def recommend_coauthors(author_id, graph, top_n=10):\n",
    "    if author_id not in graph: return []\n",
    "    current_coauthors = graph[author_id]\n",
    "    candidates = []\n",
    "    for neighbor in current_coauthors:\n",
    "        neighbors_of_neighbor = graph.get(neighbor, set())\n",
    "        for candidate in neighbors_of_neighbor:\n",
    "            if candidate != author_id and candidate not in current_coauthors:\n",
    "                candidates.append(candidate)\n",
    "    return [c[0] for c in Counter(candidates).most_common(top_n)]\n",
    "\n",
    "# --- 4. AVALIAÇÃO (PRECISION, RECALL, F1) ---\n",
    "\n",
    "K = 10  # Avaliando o Top-10 recomendações\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# Avaliamos APENAS autores que realmente formaram novas conexões\n",
    "# (Não faz sentido avaliar quem parou de publicar ou só trabalhou com velhos amigos)\n",
    "for author_id, actual_new_coauthors in test_ground_truth.items():\n",
    "    \n",
    "    # O modelo faz a predição baseada APENAS no grafo de treino\n",
    "    recommendations = recommend_coauthors(author_id, train_graph, top_n=K)\n",
    "    \n",
    "    # Se o modelo não recomendou ninguém (ex: autor isolado), precisão é 0\n",
    "    if not recommendations:\n",
    "        precisions.append(0)\n",
    "        recalls.append(0)\n",
    "        continue\n",
    "\n",
    "    # Quantos acertos (Interseção entre Recomendados e Reais)\n",
    "    hits = len(set(recommendations) & actual_new_coauthors)\n",
    "    \n",
    "    # Precision: Dos que eu recomendei, quantos eram verdadeiros?\n",
    "    p = hits / len(recommendations)\n",
    "    \n",
    "    # Recall: Dos que existiam de verdade, quantos eu encontrei?\n",
    "    r = hits / len(actual_new_coauthors)\n",
    "    \n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "\n",
    "# --- 5. RESULTADOS MÉDIOS ---\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "\n",
    "# F1 Score (Média harmônica)\n",
    "if (avg_precision + avg_recall) > 0:\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n",
    "else:\n",
    "    f1_score = 0\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Resultados da Avaliação (Top-{K}):\")\n",
    "print(f\"Precision: {avg_precision:.4f} (De cada 10 sugeridos, ~{avg_precision*10:.1f} são aceitos)\")\n",
    "print(f\"Recall:    {avg_recall:.4f} (O modelo encontra ~{avg_recall*100:.1f}% dos novos parceiros)\")\n",
    "print(f\"F1-Score:  {f1_score:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
